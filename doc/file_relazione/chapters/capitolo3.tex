\maketitle
\chapter{Analisi dell'implementazione}

In questo capitolo viene analizzato il codice sorgente del progetto, evidenziando le scelte tecniche adottate per garantire l'efficienza computazionale e il corretto interfacciamento tra i moduli in C e le routine in Assembly.

L’efficienza del sistema sviluppato non risiede esclusivamente nell'uso di istruzioni vettoriali, ma nasce da una progettazione precisa  dell’interfaccia tra i diversi livelli del software. 

Il punto di giunzione fondamentale tra l’astrazione del linguaggio C e la rigidità dell'Assembly è rappresentato dalla struttura input\_data.

 Questa non deve essere intesa come un semplice contenitore passivo di variabili, ma come il vero nucleo operativo che permette di superare i limiti intrinseci del passaggio dei parametri tra linguaggi di diverso livello.

In un'architettura a 32 bit, il passaggio di numerosi argomenti (come i puntatori alle matrici del dataset, delle query, dei pivot e i parametri di controllo $k$, $h$, $x$) graverebbe pesantemente sullo stack, introducendo un overhead che vanificherebbe i guadagni prestazionali della vettorizzazione. 

L'adozione della struttura input\_data permette invece di passare un unico indirizzo di memoria alla routine Assembly, la quale può poi navigare tra i dati con estrema precisione.

Questa "giunzione" è resa possibile dalla definizione di offset mnemonici che mappano la memoria fisica: nel codice Assembly, il riferimento a un dato non avviene tramite il nome della variabile, ma calcolando la distanza in byte dall'inizio della struttura. Ad esempio, l'accesso alla dimensionalità $D$ o al numero di query $nq$ viene gestito puntando agli indirizzi precisi (come [RDI+64] o [RDI+68]), garantendo che il codice a basso livello operi esattamente sugli stessi dati manipolati dal C, senza alcuna ambiguità o spreco di cicli di clock per la gestione dei parametri.

\section{Gestione della memoria e allineamento dati}
L’efficienza delle istruzioni SIMD (SSE e AVX) è strettamente legata alla modalità con cui i dati vengono caricati dai banchi di memoria ai registri della CPU. Analizzando il modulo $matrix.c$, si osserva come l'allocazione del dataset e delle query non avvenga tramite una semplice funzione malloc, ma segua rigorosi vincoli di allineamento.

Per poter utilizzare istruzioni di caricamento rapido, come MOVAPS per SSE o VMOVAPD per AVX, i puntatori base delle matrici devono essere allineati a confini di 16 o 32 byte. Nel progetto, questa necessità è gestita tramite funzioni di allocazione specifica che garantiscono che l'indirizzo di memoria restituito sia un multiplo della dimensione del registro di destinazione. Tale accorgimento previene le penalità di performance dovute ai "misaligned accesses", che costringerebbero la CPU a eseguire cicli di lettura supplementari, riducendo drasticamente il throughput dei dati durante il calcolo delle distanze.

\section{Modularità e setting dei target di compilazione}
Ci siamo poi occupati di andare a definire diversi target di compilazione: Release\_Scalar, Release\_SSE2 e Release\_AVX64. Questa separazione riflette una scelta implementativa precisa: mantenere un'unica logica di controllo in C capace di invocare diverse implementazioni del "back-end" computazionale.

I file distance.c e quantization.c fungono da strato di astrazione. Essi contengono le versioni scalari scritte in C, utilizzate come riferimento per la validazione dei risultati (baseline), e le dichiarazioni delle funzioni extern implementate in Assembly. Questo approccio modulare permette al compilatore di linkare le routine ottimizzate solo quando il target specifico lo richiede, garantendo che la versione a 32 bit float non venga inquinata da logiche a 64 bit double, e viceversa. Tale distinzione è fondamentale per testare accuratamente lo speedup ottenuto attraverso la vettorizzazione rispetto al codice sequenziale puro.

\section{Vettorizzazione e calcolo parallelo nei registri SIMD}
Analizzando i file quantpivot32.nasm e quantpivot64.nasm, emerge chiaramente come il calcolo della distanza euclidea sia stato trasformato da una sequenza di operazioni scalari a un flusso vettorializzato.

Invece di iterare singolarmente su ogni dimensione $D$ dei vettori, il codice sfrutta i registri XMM (per la versione SSE a 32 bit) e YMM (per la versione AVX a 64 bit).

L'implementazione non si limita a caricare i dati, ma ottimizza il ciclo di calcolo $(a-b)^2$ riducendo al minimo gli accessi alla memoria attraverso l'utilizzo di istruzioni come SUBPS e MULPS. 

Analizzando il loop principale, si nota l'utilizzo di istruzioni come SUBPS e MULPS. La strategia adottata prevede il caricamento di un blocco di componenti (4 float o 4 double) in un registro, la sottrazione simultanea con il corrispondente blocco del secondo vettore e l'elevamento al quadrato del risultato moltiplicando il registro per se stesso.

Un dettaglio tecnico fondamentale risiede nella gestione della riduzione orizzontale: dopo aver accumulato i quadrati delle differenze nei canali del registro vettoriale, il codice utilizza l'istruzione HADDPS (Horizontal Add Packed Single) nella versione SSE. Questa istruzione permette di sommare le componenti adiacenti all'interno dello stesso registro con un'unica operazione hardware, eliminando la necessità di complesse sequenze di shuffle e addizioni scalari, velocizzando così l'ottenimento della distanza parziale da confrontare con la soglia di pruning.

\section{Ottimizzazione del Controllo di Flusso e Loop Unrolling}

Un ulteriore livello di accuratezza è garantito dalla gestione della dimensionalità $D$.

 Poiché non è garantito che $D$ sia un multiplo esatto della dimensione dei registri SIMD (4 elementi per SSE o 8 per AVX), il codice implementa una gestione specifica dei resti). 

Al termine del loop principale vettorializzato, è presente una sezione di "cleanup" scalare che processa le ultime componenti rimanenti. Questo assicura che il calcolo della distanza sia matematicamente esatto per qualsiasi dimensione del dataset, evitando al contempo accessi a zone di memoria non allocate che causerebbero errori di segmentazione.

Un'altra tecnica utilizzata in questa parte è la Loop Unrolling: invece di processare un singolo blocco vettoriale per ogni iterazione, il codice è strutturato per gestire più blocchi contemporaneamente. 

Questa scelta riduce l'incidenza delle istruzioni di controllo del ciclo (incremento del contatore e salto condizionato) e permette alla CPU di sfruttare meglio il pipelining interno mantenendo le unità di esecuzione sempre alimentate.

Inoltre, l'interazione tra il codice Assembly e la logica di pruning descritta precedentemente è gestita in questo modo: le routine Assembly restituiscono il controllo al chiamante C non appena viene superata la soglia di distanza massima, oppure procedono al caricamento dei dati successivi se il punto è ancora un potenziale candidato. 

Questo meccanismo è implementato tramite salti condizionali ottimizzati che tengono conto della predizione dei rami della CPU, evitando che un calcolo inutile rallenti l'intero processo di ricerca dei vicini.

\section{Implementazione della quantizzazione e della distanza approssimata}

Il processo di quantizzazione, implementato nelle routine Assembly, rappresenta il secondo livello di filtraggio del sistema. 

L'analisi del codice rivela come il software trasformi i vettori ad alta dimensionalità in una coppia di maschere binarie, $v^+$ e $v^-$. 

Questo passaggio non è una semplice riduzione di precisione, ma una vera e propria estrazione delle componenti con modulo maggiore.

Per identificare le $x$ componenti più significative, il codice Assembly utilizza un approccio basato sull'analisi delle singole componenti del vettore.

La soglia di magnitudo utilizzata per generare le maschere binarie non è un valore statico, ma viene calcolata dinamicamente nel modulo C in base al parametro $x$. In Assembly, tale soglia viene "propagata" su tutti i canali del registro, permettendo all'istruzione CMPPS di confrontare l'intero blocco vettoriale in un unico ciclo di clock. Quindi attraverso l'istruzione di confronto vettoriale CMPPS (o VCMPPD in AVX), la CPU confronta simultaneamente 4 o 8 componenti con una soglia pre-calcolata. 

Il risultato di questo confronto è una maschera di bit che viene poi salvata nei buffer temporanei.

Come spiegato precedentemente, ora è il momento del calcolo della distanza approssimata $\tilde{d}$, che serve per risparmiare calcoli e quindi potenza computazionale ed evitare di calcolare la distanza matematicamente corretta per ogni vettore. 

Una volta ottenute le maschere binarie per la query e per il punto del dataset, il prodotto scalare tra vettori binari viene risolto tramite operazioni logiche AND seguite dall'istruzione POPCNT (Population Count). Quest'ultima istruzione hardware conta il numero di bit impostati a 1 in un registro in un singolo ciclo di clock. 

Questa scelta implementativa permette di sostituire centinaia di moltiplicazioni e somme in virgola mobile con poche operazioni bit-a-bit, accelerando la stima della distanza prima di decidere se procedere o meno con il calcolo euclideo esatto.

\section{Gestione dei buffer temporanei}

All'interno del file quantpivot32.nasm si può notare che la gestione di queste maschere binarie richiede memoria temporanea supplementare. Per evitare la frammentazione della memoria o rallentamenti dovuti a continue chiamate di sistema, il codice utilizza le macro getmem e fremem.

Queste macro agiscono come un'interfaccia sicura verso le funzioni di gestione dei blocchi di memoria definite in C e sono anche progettate per rispettare rigorosamente le convenzioni di chiamata (Application Binary Interface - ABI). 

All'ingresso della routine, il codice Assembly si occupa di preservare lo stato dei registri "callee-saved" (come ESI, EDI e EBX nella versione a 32 bit), ripristinandoli correttamente prima del ritorno al chiamante. Questo garantisce la stabilità dell'intero applicativo, evitando che la sovrascrittura accidentale di registri critici durante l'allocazione della memoria provochi crash al ritorno della funzione.

Questo controllo rigoroso previene i memory leak che, in un algoritmo che deve processare migliaia di query su dataset importanti, porterebbero rapidamente all'esaurimento delle risorse di sistema.